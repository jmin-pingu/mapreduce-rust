use mr::{
    ds::{
        task::TaskType, 
        intermediate::Intermediate, 
    },
    worker::ReduceType,
    rpc::TaskServiceClient,
};
use std::{
    net::SocketAddr,
    time, 
    hash::{Hasher, Hash, DefaultHasher},
    thread,
    fs,
    io::prelude::*, 
    path, 
    io,
};
use tarpc::{
    client, 
    client::RpcError, 
    context, 
    tokio_serde::formats::Json
};
use plugins_core::ds::KeyValue;
use serde_json;
use clap::Parser;

/// hash: Calculates the hash for a generic T that implements Hash
fn hash<T: Hash>(t: &T) -> u64 {
    let mut s = DefaultHasher::new();
    t.hash(&mut s);
    s.finish()
}

// NOTE: maybe instead of using a worker function, we can use a worker struct that implements
// certain behavior

/// Description
///
/// Arguments
pub fn create_worker(
    id: i8, 
    reduce_type: ReduceType,
) {
    // create our functions table and load the plugin
    let mut functions = mr::ExternalFunctions::new();

    unsafe {
        functions
            .load("../target/debug/libplugins_mrapp.so")
            .expect("Function loading failed");
    }

    // NOTE: RPC GetTask
    let s = "Hello".to_string();
    println!("{}", hash(&s) % 12);
    let delay = time::Duration::from_millis(250);

    println!("{:#?}", TaskType::Map);
    println!("{:#?}", TaskType::Reduce);
    println!("Worker {}", id);
    loop {
        println!("sleeping for 500 millis");
        thread::sleep(delay);
        // do_map(mapf);
        // TODO: depending on ReduceType, eagerly get reduce tasks when available or wait for no
        match reduce_type {
            ReduceType::Expedited => {
                println!("expedited");
            }
            ReduceType::Traditional => {
                println!("traditional");
            }
        }
        // map tasks 
        // do_reduce(reducef);
        // information from the mapf
    }
    
}

#[derive(Parser)]
struct Flags {
    /// Sets the server address to connect to.
    #[clap(long)]
    server_addr: SocketAddr,
}

#[tokio::main]
pub async fn main() {
    let x: String = "Hello World".to_string();
    let handle = thread::spawn(move ||
        send_echo(x)
    );
    println!("{:#?}", handle.join().unwrap());
}

// Define client-side RPC calls
#[tokio::main]
pub async fn send_echo(arg: String) -> Result<String, RpcError> {
    let flags = Flags::parse();
    let mut transport = tarpc::serde_transport::tcp::connect(flags.server_addr, Json::default);

    transport.config_mut().max_frame_length(usize::MAX);
    // TaskServiceClient is generated by the #[tarpc::service] attribute. It has a constructor `new`
    // that takes a config and any Transport as input.
    let client: TaskServiceClient = TaskServiceClient::new(client::Config::default(), transport.await.unwrap()).spawn();

    // The client has an RPC method for each RPC defined in the annotated trait. It takes the same
    // args as defined, with the addition of a Context, which is always the first arg. The Context
    // specifies a deadline and trace information which can be helpful in debugging requests.
    client.echo(context::current(), arg).await
}


#[tokio::main]
pub async fn send_get_task(id: i8, task_type: Option<TaskType>) -> Result<(Option<String>, bool), RpcError> {
    let flags = Flags::parse();
    let mut transport = tarpc::serde_transport::tcp::connect(flags.server_addr, Json::default);

    transport.config_mut().max_frame_length(usize::MAX);
    let client: TaskServiceClient = TaskServiceClient::new(client::Config::default(), transport.await.unwrap()).spawn();
    client.get_task(context::current(), id, task_type).await
}


#[tokio::main]
pub async fn send_completed_task(task: String) -> Result<bool, RpcError> {
    let flags = Flags::parse();
    let mut transport = tarpc::serde_transport::tcp::connect(flags.server_addr, Json::default);

    transport.config_mut().max_frame_length(usize::MAX);
    let client: TaskServiceClient = TaskServiceClient::new(client::Config::default(), transport.await.unwrap()).spawn();
    client.completed_task(context::current(), task).await
}

/// read_file: 
fn read_file(file_name: String) -> (String, String) {
    let contents = fs::read_to_string(file_name.clone()).expect("Should have been able to read file");
    (file_name, contents)
}

/// Description
///
/// Arguments
fn do_map(filename: String, functions: &mr::ExternalFunctions) -> Vec<KeyValue> { 
    let (filename, contents) = read_file(filename);
    functions
        .call_mapf(filename, contents)
        .expect("Invocation failed")
}

/// Description
///
/// Arguments
///
// TODO: come up with a better name for preparing the output KeyValue's of mapf for nreduce reducef
// tasks
fn prepare_for_reduce(map_task_num: usize, nreduce: usize, kva: Vec<KeyValue>) {
    // Initialize the vector of nreduce temporary files
    let mut files: Vec<fs::File> = Vec::with_capacity(nreduce);
    for reduce_task_num in 0..nreduce {
        let file = fs::File::create(format!("{:#?}/mr-{}-{}", std::env::current_dir().unwrap().into_os_string().into_string(), map_task_num, reduce_task_num)).unwrap();
        files.push(file);
    }

    // Add all KeyValue's to appropriate intermediate files
    kva.into_iter().for_each(|kv| {
        let data = format!("{}\n", serde_json::to_string(&kv).unwrap());
        (&files[hash::<String>(&kv.key) as usize % nreduce])
            .write(data.as_bytes())
            .expect("Unable to write to intermediate file"); 
    });
}

/// Description
///
/// Arguments
/// * `filename`
/// * `reducef`
///
// NOTE: Need a lock around reduce tasks
// NOTE: how to wait for all map tasks to complete
fn do_reduce(filename: String, functions: &mr::ExternalFunctions) {
    let mut intermediate: Intermediate = Intermediate::new();

    // Get the reduce task number from the filename, DO NOT move the filename since we still need
    // to read lines from the filename
    let re = regex::Regex::new(r"mr-[0-9]+-(?<reduce_num>[0-9]+)").expect("regex pattern invalid");
    let capture_group = re.captures(&filename).expect("filename is incorrect");
    let reduce_task_num = (&capture_group)["reduce_num"].to_string();

    // Read lines from file into Intermediate
    if let Ok(lines) = read_lines(filename.clone()) {
        lines.flatten().for_each(|line| {
            let kv: KeyValue = serde_json::from_str(&line).unwrap();
            intermediate.insert(kv.key, kv.value);
        });    
    };

    // Open reducef (create if it doesn't exist, append if it does)
    let mut outputf = fs::OpenOptions::new()
        .append(true)
        .create(true)
        .open(format!("mr-out-{}", reduce_task_num))
        .expect("Failed to open output reduce file");

    // Apply reducef to the values in intermediate to a file
    intermediate.0 // TODO: impl Iterator for Intermediate
        .into_iter()
        .for_each(|(k, v)| {

    
            outputf.write(
                format!("{} {}\n", 
                    k.clone(), 
                    functions
                        .call_reducef(k, v)
                        .expect("Invocation failed")
                    ).as_bytes()
                ).expect("Failed to write to output file");
            }
        );
    // Delete the intermediate filename
    fs::remove_file(filename).expect("Failed to remove filename");
}

// The output is wrapped in a Result to allow matching on errors.
// Source: https://doc.rust-lang.org/rust-by-example/std_misc/file/read_lines.html
fn read_lines<P>(filename: P) -> io::Result<io::Lines<io::BufReader<fs::File>>>
where P: AsRef<path::Path>, {
    let file = fs::File::open(filename).expect("Failed to read filename");
    Ok(io::BufReader::new(file).lines())
}
